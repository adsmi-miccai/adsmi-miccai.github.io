---
layout: page
title: ADSMI @ MICCAI 2024
subtitle: MICCAI Workshop on Advancing Data Solutions in Medical Imaging AI
description: The Joint Workshop of Data Augmentation, Labeling, and Imperfections (DALI), Big Task Small Data, 1001-AI (BTSD), and Medical Image Learning with Limited and Noisy Data (MILLanD)
# carousels:
#   - images: 
#     - image: /hero.png
#     - image: /hero.png
#     - image: /hero.png
# hero_image: /logo_adsmi.png
# image: /logo_adsmi.png
# show_sidebar: true
---
<!-- {% include carousel.html height="50" unit="%" duration="7" number="1" %} -->

# ADSMI: MICCAI Workshop on Advancing Data Solutions in Medical Imaging AI

In the rapidly evolving field of Medical Imaging AI, the quest for robust, fair, and efficient computational models is more critical than ever. With the advent of advanced imaging techniques and the exponential growth in the volume and complexity of medical data, traditional machine learning approaches face significant hurdles in data solutions. The MICCAI Workshop on **A**dvancing **D**ata **S**olutions in **M**edical **I**maging AI (**ADSMI**) aims to provide a venue for discussions and innovations at the confluence of medical imaging, artificial intelligence, and data science, addressing the nuanced challenges of data scarcity, quality, and interoperability in medical imaging AI.

ADSMI is the joint workshop of Data Augmentation, Labeling, and Imperfections (DALI), Big Task Small Data, 1001-AI (BTSD-1001AI), and Medical Image Learning with Limited and Noisy Data (MILLanD).

## Important Dates

- **[Paper Submission](https://cmt3.research.microsoft.com/ADSMI2024) Opens**: **April 18**, 2024
- **Paper Submission Deadline**:  **June 24**, 2024
- **Notification to Authors**:  **July 15**, 2024
- **Camera Ready Deadline**:  **August 2**, 2024
- **Workshop Day**: **October 6**, 2024, Marrakesh, Morocco

## Call For Papers

At a critical juncture in medical imaging AI, the integration of expansive datasets, foundational models, and advanced methodologies holds the promise of transforming diagnosis, treatment planning, and patient care. Yet, this potential is frequently curtailed by inherent data-related challenges, including limited annotations, privacy issues, and the long-tail distribution of medical conditions. Furthermore, the ethical dimensions of AI—encompassing fairness, equity, and bias—demand a shift towards more inclusive, transparent, and accountable AI systems.

ADSMI is committed to nurturing a multidisciplinary dialogue that narrows the gap between technological progress and clinical application. Our agenda covers a wide array of topics, ranging from novel data synthesis methods to the compilation of comprehensive, multimodal datasets mirroring patient population diversity. We delve into the exploration of foundational model training, utilizing the capabilities of large neural networks to explore new potentials in medical image analysis, diagnosis, and tailored medicine.

The workshop also seeks contributions that advance data curation practices, algorithmic fairness, privacy protection techniques, and the establishment of benchmarks to enable fair comparisons among emerging technologies. Special interest is directed towards innovative solutions for handling noisy or incomplete data and annotations, domain adaptation, incorporation of domain-specific knowledge within AI models, and foundation model development and applications. Our objective is to foster the development of advanced AI solutions that are also practically useful and in alignment with the goals of public health and patient welfare.

We extend an invitation to researchers, clinicians, technologists, and industry stakeholders to share their insights, research findings, and future visions for data solutions in medical imaging AI. Through keynote talks, paper presentations, and interactive sessions, ADSMI endeavors to stimulate the development of AI solutions that are technologically sound, ethically grounded, and universally accessible. Our topics of interest include but not limited to:

- Innovations in semi-, weakly-, and self-supervised learning.
- Multi-modal and synthetic data utilization.
- Domain adaptation, generalization, and learning from limited datasets.
- Enhancements in data annotation efficiency and strategies for managing label imperfections.
- Development and evaluation of new datasets aligned with the workshop's themes.
- Foundation model development and applications for medical image analysis.
- Exploration of zero-shot learning in medical image analysis for recognition, detection, and segmentation.
- Efficient annotation methodologies employing one-shot or few-shot learning.
- Techniques for synthesizing medical images across diverse modalities, imaging sites, and from textual descriptions.
- Ethical considerations in AI-driven medical imaging, focusing on fairness, equity, and privacy.

Submissions to our workshop will be managed using the same platform as the main MICCAI conference, using Microsoft CMT. Workshop paper submission website is at: [https://cmt3.research.microsoft.com/ADSMI2024](https://cmt3.research.microsoft.com/ADSMI2024)

The ADSMI workshop will employ the same reviewing standards as the main conference. ADSMI workshop paper submissions should be anonymized to accommodate a double-blind review. Papers should be formatted using LaTeX or MS Word templates available at [Lecture Notes in Computer Science](https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines). Manuscripts should be up to 8 pages (text, figures, and tables) plus up to 2 pages of references. In submitting a paper, authors implicitly acknowledge that no paper of substantially similar content has been or will be submitted to another conference or workshop until the decisions have been made by our workshop. Supplemental material submission is optional, which may include:

- Videos of results that cannot be included in the main paper
- Anonymized related submissions to other conferences and journals
- Appendices or technical reports containing extended proofs and mathematical derivations that are not essential for the understanding of the paper

Contents of the supplemental material should be referred to appropriately in the paper, and reviewers are not obliged to look at it.

<!-- ## Camera Ready Submission Guidelines

Please carefully address the feedback provided by the reviewers. Submit the revised materials to the [DALI CMT site](https://cmt3.research.microsoft.com/DALI2023) as a single zip archive, named in the format `dali23_id-X.zip`, with "X" being replaced by your unique paper ID.

Your submission should include:

1. **Manuscript**: Maximum of 8.5 pages, inclusive of text, figures, and tables, with an additional allowance of up to 2 pages for references. The file should be named `manuscript.pdf`.
2. **Supplementary Material** (Optional): Name the file `supplementary_material.pdf`. Note that source files for supplementary materials aren't mandatory.
3. **Changes Document**: A detailed list of modifications made post-review. Name the file `changes_after_review.pdf`.
4. **Copyright Form**: Download and fill out the [copyright form](https://dali-miccai.github.io/DALI23_SNCS_ProceedingsPaper_LTP_ST_SN_Switzerland.docx). The form should be signed by the corresponding author. Digital signatures will not be accepted. Save this document as `copyright.pdf`.
5. **Source Files**: Include a folder named `src/`, which houses the source files for your manuscript (e.g., `.tex`, `.bib`, `.docx`).

To ensure your paper is presented at MICCAI DALI 2023, a minimum of one paper author **must** register to attend on the second workshop day, October 12. As a general rule, this registration should be an "in-person" registration. The camera-ready submission portal will prompt you to provide the registration number of the author who will be presenting your work. -->

## Program

<!-- ### Location

- **Workshop: Meeting Room 14, Vancouver Convention Center East Building Level 1**
- **Coffee Break/Poster Session: The Poster Hall at Ground Level Exhibition B-C**
- **Virtual Attendance: ConFLUX platform**  -->

### Keynote Speakers

- TBD

<!-- - [Dimitris N. Metaxas](https://people.cs.rutgers.edu/~dnm/), Rutgers University, USA [\[Keynote Info\]](talks/Dimitris_Metaxas.html)
- [Lena Maier-Hein](https://www.dkfz.de/en/imsy/team/people/Lena_Maier-Hein.html), German Cancer Research Center, Germany [\[Keynote Info\]](talks/Lena_Maier-Hein.html)
- [Paul M. Thompson](https://keck.usc.edu/faculty-search/paul-m-thompson/), University of Southern California, USA [\[Keynote Info\]](talks/Paul_Thompson.html) -->

<!-- ### Schedule

- <ins>1:30 - 1:40 PM PDT</ins> Opening, welcome and introduction
- <ins>1:40 - 1:55 PM PDT</ins> **Oral: Masked Conditional Diffusion Models for Image Analysis with Application to Radiographic Diagnosis of Infant Abuse**,  *Andy Tsai (Boston Children's Hospital and Harvard Medical School)*
- <ins>1:55 - 2:10 PM PDT</ins> **Oral: Self-Supervised Single-Image Deconvolution with Siamese Neural Networks**,  *Mikhail Papkov (University of Tartu)*
- <ins>2:10 - 2:50 PM PDT</ins> **Keynote: The devil is in the details: On the importance of professionalizing the whole image analysis pipeline**, *[Lena Maier-Hein](https://www.dkfz.de/en/imsy/team/people/Lena_Maier-Hein.html) (German Cancer Research Center)*; [\[Details\]](talks/Lena_Maier-Hein.html)
- <ins>2:50 - 3:30 PM PDT</ins> **Keynote: Genetic Mutation and Biological Pathway Prediction from Whole Slide Images using Deep Learning for Cancer Detection and Diagnosis**, *[Dimitris N. Metaxas](https://people.cs.rutgers.edu/~dnm/) (Rutgers University)*; [\[Details\]](talks/Dimitris_Metaxas.html)
- <ins>3:30 - 4:00 PM PDT</ins> Coffee Break/Poster Session (Ground Level Exhibition B-C)
- <ins>4:00 - 4:30 PM PDT</ins> Poster Session (Ground Level Exhibition B)
- <ins>4:30 - 5:10 PM PDT</ins> **Keynote: AI and Data Efficient Deep Learning to Accelerate Large-Scale Studies of Brain Diseases**, *[Paul M. Thompson](https://keck.usc.edu/faculty-search/paul-m-thompson/) (University of Southern California)*; [\[Details\]](talks/Paul_Thompson.html)
- <ins>5:10 - 5:25 PM PDT</ins> **Oral: Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports**,  *Tom J van Sonsbeek (University of Amsterdam)*
- <ins>5:25 - 5:40 PM PDT</ins> **Oral: Data Augmentation Based on DiscrimDiff for Histopathology Image Classification**,  *Xianchao Guan (Harbin Institute of Technology, Shenzhen)*
- <ins>5:40 - 5:55 PM PDT</ins> **Oral: URL: Combating Label Noise for Lung Nodule Malignancy Grading**,  *Xianze Ai (Northwestern Polytechnical University)*
- <ins>5:55 - 6:10 PM PDT</ins> **Oral: A Realistic Collimated X-Ray Image Simulation Pipeline**,  *Benjamin El-Zein (Friedrich-Alexander-University Erlangen-Nuremberg)*
- <ins>6:10 - 6:30 PM PDT</ins> Closing and award announcement

### Poster List (Ground Level Exhibition B)

- <ins>01</ins> URL: Combating Label Noise for Lung Nodule Malignancy Grading
- <ins>02</ins> Zero-shot Learning of Individualized Task Contrast Prediction from Resting-state Functional Connectomes
- <ins>03</ins> Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis
- <ins>04</ins> A Unified Approach to Learning with Label Noise and Unsupervised Confidence Approximation
- <ins>05</ins> Transesophageal Echocardiography Generation using Anatomical Models
- <ins>06</ins> Data Augmentation Based on DiscrimDiff for Histopathology Image Classification
- <ins>07</ins> Clinically Focussed Evaluation of Anomaly Detection and Localisation Methods Using Inpatient CT Head Data
- <ins>08</ins> LesionMix: A Lesion-Level Data Augmentation Method for Medical Image Segmentation
- <ins>09</ins> Knowledge Graph Embeddings for Multi-Lingual Structured Representations of Radiology Reports
- <ins>10</ins> Modular, Label-Efficient Dataset Generation for Instrument Detection for Robotic Scrub Nurses
- <ins>11</ins> Adaptive Semi-Supervised Segmentation of Brain Vessels with Ambiguous Labels
- <ins>12</ins> Proportion Estimation by Masked Learning from Label Proportion
- <ins>13</ins> Active Learning Strategies on a Real-World Thyroid Ultrasound Dataset
- <ins>14</ins> A Realistic Collimated X-Ray Image Simulation Pipeline
- <ins>15</ins> Masked Conditional Diffusion Models for Image Analysis with Application to Radiographic Diagnosis of Infant Abuse
- <ins>16</ins> Self-Supervised Single-Image Deconvolution with Siamese Neural Networks

## Awards and Sponsors

TBD


<!-- ## Paper Presentation Guidelines

Each accepted paper will be given eleven minutes for presentation and Q&A. In-person presentations are highly recommended, but remote virtual presentations can be accommodated. Please complete the [survey form](https://docs.google.com/forms/d/112VBP1Zft_LDDIPivIcRXPJvsMF4POx31o10zRUQfkU) as soon as possible **by September 14th** to inform the workshop organizers about your presentation format (in-person or virtual) and the presenter of your paper.

Every accepted paper should upload the presentation slides in .pptx format. If your paper will be presented virtually, you are also required to upload a video of your presentation that is 8-9 minutes in length. Authors presenting in-person are strongly recommended to upload a video but they are not required to do so. Please name your files with a prefix that is your DALI22 paper id, e.g. dali22_id-X.pptx where X is replaced by your paper ID. The powerpoint slides and videos should be uploaded to the [Google Drive folder](https://drive.google.com/drive/folders/1vZE40Eq9XV2yr_SwZtP6UlzdA4BXgaIh), **no later than Monday, September 19th**. Please note that you may be asked to sign into one of your google accounts before accessing and uploading files to the folder above. If you encounter difficulty with login, please email Sharon Huang (suh972@psu.edu) and ask for an alternative way of uploading files.

The presenting author should be registered for the second workshop day (September 22) of the MICCAI conference. Via [pathable](https://miccai2022.pathable.eu/), the DALI workshop event can be added to your agenda. The physical event will be held in Room Aquarius 1, 8:00am-3:00pm SGT. Virtual attendees can join the event via a zoom link provided in pathable. The zoom link to join the event should become available in pathable, shortly before the start of the event (8:00am SGT on Sep. 22). -->

<!-- ## Program
 -->


## People

### General Chairs:
- Yuan Xue, Ohio State University, USA
- Chen Chen, University of Sheffield, UK
- S. Kevin Zhou, University of Science & Technology of China, China
- Rama Chellappa, Johns Hopkins University, USA
- Sameer Antani, National Institutes of Health, USA
- Zhiyun Xue, National Institutes of Health, USA

### Executive Chairs
- Chao Chen, Stony Brook University, USA
- Esther Puyol-Antón, King's College London, UK
- Le Zhang, University of Birmingham, UK
- Bo Zhou, Northwestern University, USA
- Xueqi Guo, Yale University and Siemens Healthineers, USA
- Marleen de Bruijne, University Medical Center Rotterdam, Netherlands and the University of Copenhagen, Denmark
- Qingsong Yao, Chinese Academy of Science, China
- Sivaramakrishnan Rajaraman, National Institutes of Health, USA
- Zhaohui Liang, National Institutes of Health, USA
- Ghada Zamzmi, Food and Drug Administration, USA
- Marius George Linguraru, Children's National Hospital, USA

<!-- ### Award Committee -->
<!-- - Dimitris N. Metaxas, Rutgers University, USA -->

<!-- ### Advisory Board -->

### Program Committee

TBD
